{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Implement Forward and Back Propagation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_sigmoid(), grader_forwardprop(), grader_backprop() etc, these are the test functions.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Loading data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 6)\n",
      "(506, 5) (506,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print(data.shape)\n",
    "\n",
    "X = data[:, :5]\n",
    "y = data[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Computational graph</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/seSGbNS.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  **If you observe the graph, we are having input features [f1, f2, f3, f4, f5] and 9 weights [w1, w2, w3, w4, w5, w6,    w7, w8, w9]**.<br><br>\n",
    "*  **The final output of this graph is a value L which is computed as (Y-Y')^2** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>1: Implementing backpropagation and Gradient checking </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>REF: Check this video for better understanding of the computational graphs and back propagation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"950\"\n",
       "            height=\"500\"\n",
       "            src=\"https://www.youtube.com/embed/i94OvYb6noo\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x20cbf0e95b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('i94OvYb6noo',width=\"950\",height=\"500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*  <b>Write two functions<br>\n",
    "    *  Forward propagation</b>(Write your code in<font color='blue'> def forward_propagation()</b></font>)<br><br>\n",
    "    For easy debugging, we will break the computational graph into 3 parts.\n",
    "\n",
    "    <font color='green'><b>Part 1</b></font></b>\n",
    "    <img src='https://i.imgur.com/0xUaxy6.png'><br><br>\n",
    "    <font color='green'><b>Part 2</b></font></b><br>\n",
    "    <img src='https://i.imgur.com/J29pAJL.png'><br><br>\n",
    "    <font color='green'><b>Part 3</b></font></b>\n",
    "    <img src='https://i.imgur.com/vMyCsd9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "  <font color='green'>\n",
    "  def forward_propagation(X, y, W):\n",
    "    <font color='grey'>\n",
    "    # X: input data point, 5-d data points\n",
    "    # y: output varible\n",
    "    # W: weight array, its of length 9, <br>          W[0] corresponds to w1 in graph, <br>          W[1] corresponds to w2 in graph, <br>          ..., <br>          W[8] corresponds to w9 in graph. \n",
    "\n",
    "    # we will return the following variables\n",
    "    # exp = part1 (compute the forward propagation until exp and then store the values in exp)\n",
    "    # tanh = part2(compute the forward propagation until tanh and then store the values in tanh)\n",
    "    # sig = part3(compute the forward propagation until sigmoid and then store the values in sig)\n",
    "    # now compute remaining values from computional graph and get y'\n",
    "    # compute the value of L=(y-y')^2\n",
    "    # compute derivative of L  w.r.to Y' and store it in dl\n",
    "    # Create a dictionary to store all the intermediate values\n",
    "    # store L, exp, tanh, sig, dl variables\n",
    "    </font>\n",
    "    return (dictionary, which we might need to use for back propagation)\n",
    "  </font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  <b>Backward propagation</b>(code in<font color='blue'> def backward_propagation()</b></font>)\n",
    "    </b>\n",
    "    <pre>\n",
    "    <font color='green'>\n",
    "    def backward_propagation(L, W,dictionary):\n",
    "        <font color='grey'>\n",
    "        # L: the loss we calculated for the current point\n",
    "        # dictionary: the outputs of the forward_propagation() function\n",
    "        # compute the gradients of each weight [w1,w2,w3,...,w9]\n",
    "        # dict type to store the required variables \n",
    "        # return dW, dW is a dictionary with gradients of all the weights\n",
    "        </font>\n",
    "        return dW\n",
    "        </font>\n",
    "</font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Forward propagation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''In this function, we will compute the sigmoid(z)'''\n",
    "    # we can use this function in forward and backward propagation\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    '''In this function, we will compute the tanh(z)'''\n",
    "    return (math.exp(z) - math.exp(-z)) / (math.exp(z) + math.exp(-z))\n",
    "    \n",
    "def forward_propagation(x, y, w):\n",
    "        '''In this function, we will compute the forward propagation '''\n",
    "        # X: input data point, 5-d data points\n",
    "        # y: output varible\n",
    "        # W: weight array, its of length 9, W[0] corresponds to w1 in graph, W[1] corresponds to w2 in graph,..., W[8] corresponds to w9 in graph.  \n",
    "        \n",
    "        # Return the following variables\n",
    "        # exp = part1 (compute the forward propagation until exp and then store the values in exp)\n",
    "        # tanh = part2 (compute the forward propagation until tanh and then store the values in tanh)\n",
    "        # sig = part3 (compute the forward propagation until sigmoid and then store the values in sig)\n",
    "        # now compute remaining values from computional graph and get y'\n",
    "        # compute the value of L=(y-y')^2\n",
    "        # compute derivative of L  w.r.to Y' and store it in dl\n",
    "        # Create a dictionary to store all the intermediate values\n",
    "        # store L, exp,tanh,sig variables\n",
    "        \n",
    "        #print(\"%\"*100, w)\n",
    "        # exp\n",
    "        \n",
    "        mul1 = np.dot(w[0], x[0])\n",
    "        mul2 = np.dot(w[1], x[1])\n",
    "        add1 = mul1 + mul2; add2 = mul1 + mul2\n",
    "        mul3 = np.dot(add1, add2)\n",
    "        add3 = mul3 + w[5]\n",
    "        exp_ = math.exp(add3)\n",
    "        \n",
    "        # tanh\n",
    "        tanh_ = tanh(exp_ + w[6])\n",
    "        \n",
    "        # sigmoid\n",
    "        sin_ = math.sin( np.dot(w[2], x[2]) )\n",
    "        add4 = np.dot(w[3], x[3]) + np.dot(w[4], x[4])\n",
    "        mul4 = np.dot(sin_, add4)\n",
    "        sig_ = sigmoid(mul4 + w[7])\n",
    "        \n",
    "        y_hat = tanh_ + np.dot(sig_, w[8])\n",
    "        l = (y-y_hat)**2\n",
    "    \n",
    "        dl = 2*(y-y_hat)*-1\n",
    "        \n",
    "        d = {\"dl\":dl, \"loss\":l, \"exp\":exp_, \"tanh\":tanh_, \"sigmoid\":sig_, \"sin\":sin_, \n",
    "             \"mul1\":mul1, \"mul2\":mul2, \"add1\":add1, \"add2\":add2, \"add4\":add4}\n",
    "        #print(\"%\"*100, d)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_forwardprop(data):\n",
    "    dl = (np.round(data['dl'],4)==-1.9285)\n",
    "    loss = (np.round(data['loss'],4)==0.9298)\n",
    "    part1 = (np.round(data['exp'],4)==1.1273)\n",
    "    part2 = (np.round(data['tanh'],4)==0.8418)\n",
    "    part3 = (np.round(data['sigmoid'],4)==0.5279)\n",
    "    assert(dl and loss and part1 and part2 and part3)\n",
    "    return True\n",
    "w = np.ones(9)*0.1\n",
    "d1 = forward_propagation(X[0],y[0],w)\n",
    "#print(d1)\n",
    "grader_forwardprop(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Backward propagation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(x,w,dic):\n",
    "    '''In this function, we will compute the backward propagation '''\n",
    "    # L: the loss we calculated for the current point\n",
    "    # dictionary: the outputs of the forward_propagation() function\n",
    "    \n",
    "    # compute the gradients of each weight [w1, w2, w3, ..., w9]\n",
    "    # use dict type to store the required variables \n",
    "    # dw1 = # in dw1 compute derivative of L w.r.to w1\n",
    "    # dw2 = # in dw2 compute derivative of L w.r.to w2\n",
    "    # dw3 = # in dw3 compute derivative of L w.r.to w3\n",
    "    # dw4 = # in dw4 compute derivative of L w.r.to w4\n",
    "    # dw5 = # in dw5 compute derivative of L w.r.to w5\n",
    "    # dw6 = # in dw6 compute derivative of L w.r.to w6\n",
    "    # dw7 = # in dw7 compute derivative of L w.r.to w7\n",
    "    # dw8 = # in dw8 compute derivative of L w.r.to w8\n",
    "    # dw9 = # in dw9 compute derivative of L w.r.to w9\n",
    "\n",
    "    # return dW, dW is a dictionary with gradients of all the weights\n",
    "    #print(\"^\"*100, w)\n",
    "    \n",
    "    dW = dict()\n",
    "    dW['dw9'] = np.dot(dic['dl'], dic['sigmoid'])\n",
    "    dW['dw8'] = np.dot(dic['sigmoid'], (1-dic['sigmoid'])) * np.dot(w[8], dic['dl'])\n",
    "    dW['dw7'] = (1 - (dic['tanh']**2)) * dic['dl']\n",
    "    dW['dw6'] = np.dot(dic['exp'], dW['dw7'])\n",
    "    dW['dw5'] = np.dot(dW['dw8'], dic['sin']) * x[4]\n",
    "    dW['dw4'] = np.dot(dW['dw8'], dic['sin']) * x[3]\n",
    "    dW['dw3'] = (math.cos(dic['sin']) * (dW['dw8'] * dic['add4'])) * x[2]\n",
    "    dW['dw2'] = ((dW['dw6'] * dic['add1']) * x[1]) + ((dW['dw6'] * dic['add2']) * x[1])\n",
    "    dW['dw1'] = ((dW['dw6'] * dic['add1']) * x[0]) + ((dW['dw6'] * dic['add2']) * x[0])\n",
    "    \n",
    "    #print(dW)\n",
    "    return dW    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_backprop(data):\n",
    "    dw1=(np.round(data['dw1'],4)==-0.2297)\n",
    "    dw2=(np.round(data['dw2'],4)==-0.0214)\n",
    "    dw3=(np.round(data['dw3'],4)==-0.0056)\n",
    "    dw4=(np.round(data['dw4'],4)==-0.0047)\n",
    "    dw5=(np.round(data['dw5'],4)==-0.001)\n",
    "    dw6=(np.round(data['dw6'],4)==-0.6335)\n",
    "    dw7=(np.round(data['dw7'],4)==-0.5619)\n",
    "    dw8=(np.round(data['dw8'],4)==-0.0481)\n",
    "    dw9=(np.round(data['dw9'],4)==-1.0181)\n",
    "    assert(dw1 and dw2 and dw3 and dw4 and dw5 and dw6 and dw7 and dw8 and dw9)\n",
    "    return True \n",
    "w=np.ones(9)*0.1\n",
    "d1=forward_propagation(X[0],y[0],w)\n",
    "#print(d1)\n",
    "d1=backward_propagation(X[0],w,d1)\n",
    "#print(d1)\n",
    "grader_backprop(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color='red'>Gradient clipping</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Check this  <a href='https://towardsdatascience.com/how-to-debug-a-neural-network-with-gradient-checking-41deec0357a9'>blog link</a> for more details on Gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we know that the derivative of any function is\n",
    " \n",
    " $$\\lim_{\\epsilon\\to0}\\frac{f(x+\\epsilon)-f(x-\\epsilon)}{2\\epsilon}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  The definition above can be used as a numerical approximation of the derivative. Taking an epsilon small enough, the calculated approximation will have an error in the range of epsilon squared. \n",
    "\n",
    "*  In other words, if epsilon is 0.001, the approximation will be off by 0.00001.\n",
    "\n",
    "Therefore, we can use this to approximate the gradient, and in turn make sure that backpropagation is implemented properly. This forms the basis of <b>gradient checking!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Font color='blue'>Gradient checking example</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font >\n",
    "lets understand the concept with a simple example:\n",
    "$f(w1,w2,x1,x2)=w_{1}^{2} . x_{1} + w_{2} . x_{2}$ \n",
    "\n",
    "from the above function , lets assume $w_{1}=1$, $w_{2}=2$, $x_{1}=3$, $x_{2}=4$ the gradient of $f$ w.r.t $w_{1}$ is\n",
    "\n",
    "\\begin{array} {lcl}\n",
    "\\frac{df}{dw_{1}} = dw_{1} &=&2.w_{1}.x_{1} \\\\& = &2.1.3\\\\& = &6\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "let's calculate the aproximate gradient of $w_{1}$ as mentinoned in the above formula and considering $\\epsilon=0.0001$\n",
    "\n",
    "\\begin{array} {lcl}\n",
    "dw_1^{approx} & = & \\frac{f(w1+\\epsilon,w2,x1,x2)-f(w1-\\epsilon,w2,x1,x2)}{2\\epsilon} \\\\ & = & \\frac{((1+0.0001)^{2} . 3 + 2 . 4) - ((1-0.0001)^{2} . 3 + 2 . 4)}{2\\epsilon} \\\\ & = & \\frac{(1.00020001 . 3 + 2 . 4) - (0.99980001. 3 + 2 . 4)}{2*0.0001} \\\\ & = & \\frac{(11.00060003) - (10.99940003)}{0.0002}\\\\ & = & 5.99999999999\n",
    "\\end{array}\n",
    "\n",
    "Then, we apply the following formula for gradient check: <i>gradient_check</i> = \n",
    "$\\frac{\\left\\Vert\\left (dW-dW^{approx}\\rm\\right) \\right\\Vert_2}{\\left\\Vert\\left (dW\\rm\\right) \\right\\Vert_2+\\left\\Vert\\left (dW^{approx}\\rm\\right) \\right\\Vert_2}$\n",
    "\n",
    "The equation above is basically the Euclidean distance normalized by the sum of the norm of the vectors. We use normalization in case that one of the vectors is very small.\n",
    "As a value for epsilon, we usually opt for 1e-7. Therefore, if gradient check return a value less than 1e-7, then it means that backpropagation was implemented correctly. Otherwise, there is potentially a mistake in our implementation. If the value exceeds 1e-3, then we are sure that the code is not correct.\n",
    "\n",
    "in our example: <i>gradient_check</i> $ = \\frac{(6 - 5.999999999994898)}{(6 + 5.999999999994898)} = 4.2514140356330737e^{-13}$\n",
    "\n",
    "we can mathamatically derive the same thing like this\n",
    "\n",
    "\\begin{array} {lcl}\n",
    "dw_1^{approx} & = & \\frac{f(w1+\\epsilon,w2,x1,x2)-f(w1-\\epsilon,w2,x1,x2)}{2\\epsilon} \\\\ & = & \\frac{((w_{1}+\\epsilon)^{2} . x_{1} + w_{2} . x_{2}) - ((w_{1}-\\epsilon)^{2} . x_{1} + w_{2} . x_{2})}{2\\epsilon} \\\\ & = & \\frac{4. \\epsilon.w_{1}. x_{1}}{2\\epsilon} \\\\ & = &  2.w_{1}.x_{1}\n",
    "\\end{array}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Implement Gradient checking </font> <br>\n",
    " (code in <font color='blue'> def gradient_checking()</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<font color='green'>\n",
    "W = initilize_randomly\n",
    "def gradient_checking(data_point, W):<font color='grey'>\n",
    "    # compute the L value using forward_propagation()\n",
    "    # compute the gradients of W using backword_propagation()</font>\n",
    "    approx_gradients = []\n",
    "\n",
    "    for each wi weight value in W:<font color='grey'>\n",
    "        # add a small value to weight wi, and then find the values of L with the updated weights\n",
    "        # subtract a small value to weight wi, and then find the values of L with the updated weights\n",
    "        # compute the approximation gradients of weight wi</font>\n",
    "        approx_gradients.append(approximation gradients of weight wi)<font color='grey'>\n",
    "\n",
    "    # compare the gradient of weights W from backword_propagation() with the aproximation gradients of weights with <br>  gradient_check formula</font>\n",
    "    return gradient_check</font>\n",
    "\n",
    "<b>NOTE: we can do sanity check by checking all the return values of gradient_checking(),<br> they have to be zero. if not we have bug in our code\n",
    "</pre></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Implement gradient checking</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://cs231n.github.io/neural-networks-3/\n",
    "def gradient_checking(x, y, w_, e):\n",
    "    d_ = forward_propagation(x, y, w_)\n",
    "    gr = backward_propagation(x, w_, d_)\n",
    "    gr = list(gr.values())\n",
    "    \n",
    "    approx_gradients = []\n",
    "    for wi in range(len(w_)):\n",
    "        wi_plus = np.copy(w_)\n",
    "        wi_plus[wi] = wi_plus[wi]+e\n",
    "        dwi_plus = forward_propagation(x, y, wi_plus)\n",
    "        \n",
    "        wi_minus = np.copy(w_)\n",
    "        wi_minus[wi] = wi_minus[wi]-e\n",
    "        dwi_minus = forward_propagation(x, y, wi_minus)\n",
    "        \n",
    "        approx_gr = (dwi_plus['loss'] - dwi_minus['loss']) / (2*e)\n",
    "        approx_gradients.append(approx_gr)\n",
    "        \n",
    "    '''\n",
    "    num = np.linalg.norm(np.array(gr) - np.array(approx_gradients))\n",
    "    den = max(np.linalg.norm(gr) , np.linalg.norm(approx_gradients))\n",
    "    diff = num / den\n",
    "    '''\n",
    "    diff_ = []\n",
    "    for g, a in zip(gr[::-1], approx_gradients):\n",
    "        diff = (g-a) / (g+a)\n",
    "        diff_.append(diff)\n",
    "        \n",
    "        if diff < e:\n",
    "            print(\"The gradient is correct\", g, a, diff)\n",
    "        else:\n",
    "            print(\"The gradient is wrong\", g, a, diff)\n",
    "    \n",
    "    return diff_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.normal(0, 0.1, 9)\n",
    "e = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient is correct 0.17294673635552799 0.17294673418599693 6.2722521226288806e-09\n",
      "The gradient is correct 0.016115983822719955 0.01611598382189605 2.5561686290841648e-11\n",
      "The gradient is correct 0.009758163765861683 0.009758137990978355 1.3206848125991673e-06\n",
      "The gradient is correct -0.0021562610407846253 -0.002156261038610552 5.041303861788948e-10\n",
      "The gradient is correct -0.00046649655226664355 -0.00046649655360830877 -1.4380226547039143e-09\n",
      "The gradient is correct -1.0965466022917905 -1.096546599130832 1.44132423641611e-09\n",
      "The gradient is correct -1.1591608760219467 -1.1591608814687238 -2.3494482643776186e-09\n",
      "The gradient is correct -0.05132840745289063 -0.05132840740773581 4.3986185862586795e-10\n",
      "The gradient is correct -1.1125189478801314 -1.1125189478811137 -4.4148701200087144e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.2722521226288806e-09,\n",
       " 2.5561686290841648e-11,\n",
       " 1.3206848125991673e-06,\n",
       " 5.041303861788948e-10,\n",
       " -1.4380226547039143e-09,\n",
       " 1.44132423641611e-09,\n",
       " -2.3494482643776186e-09,\n",
       " 4.3986185862586795e-10,\n",
       " -4.4148701200087144e-13]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_checking(X[0], y[0], W, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
