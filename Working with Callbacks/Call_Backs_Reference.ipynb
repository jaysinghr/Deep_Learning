{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"gjzTYtr1OMW3"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K0WP3DUvOMW_"},"source":["## 1.1 Addition\n","It is similar to numpy addition."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","id":"qcKl2W9qOMXC","outputId":"5ea26b1e-158e-493b-8a3c-8882931065fa"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.74210405, 0.17488694],\n","       [0.46748793, 0.11850929]], dtype=float32)>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(2,2))\n","a"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","id":"COUVYv5BOMXO","outputId":"2e4e19dd-fdab-458e-aa53-f6029a50430e"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.0908494 , 0.4744984 ],\n","       [0.46770465, 0.09530127]], dtype=float32)>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["b = tf.random.uniform(shape=(2,2))\n","b"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","id":"7I1KMCgiOMXV"},"outputs":[],"source":["add = a + b"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","id":"ksQu6lT6OMXa","outputId":"9fdcd302-7fb3-494f-94b3-2b28ac701c13"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.83295345, 0.64938533],\n","       [0.9351926 , 0.21381056]], dtype=float32)>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["add"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YPxWE4stOMXe"},"source":["#### Broadcasting works similar to numpy."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{},"colab_type":"code","id":"kKaICOghOMXg"},"outputs":[],"source":["c = 2.0"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{},"colab_type":"code","id":"7pINN69LOMXn"},"outputs":[],"source":["add_2 = a + c"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","id":"LIaJTqAwOMXr","outputId":"c510312e-78e7-45d0-d40d-52780d62b18c"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[2.742104 , 2.174887 ],\n","       [2.4674878, 2.1185093]], dtype=float32)>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["add_2"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1rOJ8iYoOMXw"},"source":["## 1.2 Subtraction\n","It is similar to numpy Subtraction."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{},"colab_type":"code","id":"x8o22IU7OMXy","outputId":"9bfb179f-8fad-4ef5-cdc6-7b918e37ac6e"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.71808827, 0.8713999 ],\n","       [0.85514164, 0.17284203]], dtype=float32)>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(2,2))\n","a"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","id":"IUEmz0MKOMX5","outputId":"87012331-692b-4218-d7ff-33b2d97c0a1f"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.24881303, 0.42708373],\n","       [0.00099826, 0.10543585]], dtype=float32)>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["b = tf.random.uniform(shape=(2,2))\n","b"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{},"colab_type":"code","id":"vlGlc6CZOMX8"},"outputs":[],"source":["sub = a - b"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{},"colab_type":"code","id":"mEst3O84OMYB","outputId":"36456888-3567-4e6e-df04-9cc606fd3b63"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.46927524, 0.44431615],\n","       [0.8541434 , 0.06740618]], dtype=float32)>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["sub"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0fjRvsmIOMYG"},"source":["## 1.3 Multiplication\n","\n","- For two dimensional matrices, you can multiply (m*n) and (n*p) and get (m*p)\n","- for 3 dim matrices, you can multiply (b * n * p)  and (b * p * m)  and get (b * n * m). ( for any dim, we have to maintain last 2 dim as two dim multiplication and first n-2 dim has to be same. we will get better idea if we go through all the operation which we have written below.)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{},"colab_type":"code","id":"OwTNd9c9OMYI","outputId":"b7b2476c-db99-405d-e6f9-b09d9680adc7"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.23715031, 0.7042936 ],\n","       [0.6522784 , 0.90400934],\n","       [0.4094566 , 0.98358476]], dtype=float32)>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2))\n","a"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{},"colab_type":"code","id":"9Z3SOY-9OMYL","outputId":"3a2c4ef2-bf07-44d3-dda3-0d51c21aee48"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n","array([[0.6622703 , 0.690899  , 0.30486214, 0.23566651],\n","       [0.99156964, 0.97543776, 0.75613225, 0.05987465]], dtype=float32)>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["b = tf.random.uniform(shape=(2,4))\n","b"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{},"colab_type":"code","id":"4PKZKq6COMYP","outputId":"858e7e21-e17e-486d-8089-d56ac69f356f"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n","array([[0.8554138 , 0.85084146, 0.6048373 , 0.09805772],\n","       [1.3283728 , 1.3324634 , 0.8824056 , 0.20784743],\n","       [1.2464638 , 1.2423189 , 0.868548  , 0.15538701]], dtype=float32)>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tf.matmul(a, b)# (3*2)@(2*4) = (3*4)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{},"colab_type":"code","id":"SKVwmcKROMYY","outputId":"91d8271f-1792-4f19-8997-785831f47032"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2, 4), dtype=float32, numpy=\n","array([[[0.13698697, 0.17825031, 0.8351407 , 0.966292  ],\n","        [0.54821014, 0.00312161, 0.02481759, 0.00539768]],\n","\n","       [[0.6668303 , 0.29011464, 0.1444956 , 0.6733773 ],\n","        [0.18880916, 0.47303724, 0.71398425, 0.36836767]],\n","\n","       [[0.5087024 , 0.8253002 , 0.0447067 , 0.5614886 ],\n","        [0.23733759, 0.6185924 , 0.41949773, 0.97963953]]], dtype=float32)>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2,4))\n","a"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{},"colab_type":"code","id":"mzkP827ROMYd","outputId":"f4982e2e-0f8b-4a2a-f552-b5bc5797e5e7"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 4, 3), dtype=float32, numpy=\n","array([[[0.00129962, 0.90050673, 0.6187657 ],\n","        [0.10942495, 0.22752917, 0.06071293],\n","        [0.46656   , 0.3667239 , 0.48753726],\n","        [0.0035224 , 0.255098  , 0.85282266]],\n","\n","       [[0.59677374, 0.6890458 , 0.0487982 ],\n","        [0.612115  , 0.28361738, 0.8172617 ],\n","        [0.6105542 , 0.3772961 , 0.9996798 ],\n","        [0.71494126, 0.8400972 , 0.4565419 ]],\n","\n","       [[0.6912173 , 0.9459939 , 0.10406113],\n","        [0.52385914, 0.22174835, 0.4774611 ],\n","        [0.8422066 , 0.62030745, 0.10736108],\n","        [0.42591286, 0.753083  , 0.17191815]]], dtype=float32)>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["b = tf.random.uniform(shape=(3,4,3))\n","b"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{},"colab_type":"code","id":"5czLohlFOMYg","outputId":"c786fe34-52f4-471d-fe02-dff13776af91"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2, 3), dtype=float32, numpy=\n","array([[[0.41272998, 0.71668005, 1.326823  ],\n","        [0.01265195, 0.5048553 , 0.35610592]],\n","\n","       [[1.145178  , 1.1619782 , 0.721514  ],\n","        [1.1015168 , 0.8431078 , 1.2777395 ]],\n","\n","       [[1.0607624 , 1.1148177 , 0.54831475],\n","        [1.258652  , 1.3596592 , 0.533507  ]]], dtype=float32)>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["tf.matmul(a, b) #(3*2*4)@(3*4*3) = (3*2*3)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{},"colab_type":"code","id":"c8OvUeISOMYp","outputId":"ba7ecb53-eaf5-4661-e773-afa56b29fc21"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2, 2, 4), dtype=float32, numpy=\n","array([[[[0.51481795, 0.07436132, 0.55893624, 0.0577631 ],\n","         [0.33213055, 0.74141204, 0.9319726 , 0.4771334 ]],\n","\n","        [[0.15865803, 0.6875229 , 0.43112993, 0.47309244],\n","         [0.20514977, 0.79612744, 0.10486436, 0.32998276]]],\n","\n","\n","       [[[0.9479476 , 0.68638337, 0.8111249 , 0.90401375],\n","         [0.6584871 , 0.69918025, 0.4396125 , 0.33223772]],\n","\n","        [[0.74394715, 0.6339786 , 0.47969925, 0.7747592 ],\n","         [0.91509235, 0.36302435, 0.46976435, 0.46686912]]],\n","\n","\n","       [[[0.7157885 , 0.16075659, 0.37033808, 0.32407653],\n","         [0.818768  , 0.0035826 , 0.48950863, 0.2149471 ]],\n","\n","        [[0.7593738 , 0.19917476, 0.84314144, 0.52006245],\n","         [0.38832057, 0.7112894 , 0.1694603 , 0.48777008]]]],\n","      dtype=float32)>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2,2,4))\n","a"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{},"colab_type":"code","id":"Ap6ISJUTOMYs","outputId":"85582bc7-53e7-4469-ba90-f8620c723c15"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2, 4, 3), dtype=float32, numpy=\n","array([[[[0.7123414 , 0.17120314, 0.2596228 ],\n","         [0.42547607, 0.880568  , 0.49057865],\n","         [0.99062824, 0.36442018, 0.6135267 ],\n","         [0.08297455, 0.6034932 , 0.55834746]],\n","\n","        [[0.90809155, 0.49866974, 0.87366796],\n","         [0.24840617, 0.34119284, 0.91429067],\n","         [0.16633534, 0.61452293, 0.2640339 ],\n","         [0.3786037 , 0.899914  , 0.6881746 ]]],\n","\n","\n","       [[[0.4562217 , 0.24703074, 0.29429078],\n","         [0.09262443, 0.88473225, 0.9782591 ],\n","         [0.48327792, 0.7432394 , 0.00655699],\n","         [0.73146546, 0.01142538, 0.49202287]],\n","\n","        [[0.3893497 , 0.9151609 , 0.8550935 ],\n","         [0.3208201 , 0.6302061 , 0.38869548],\n","         [0.2811669 , 0.14035869, 0.02498496],\n","         [0.7534467 , 0.97786224, 0.07732892]]],\n","\n","\n","       [[[0.07968879, 0.485206  , 0.3976016 ],\n","         [0.79267263, 0.964952  , 0.53720546],\n","         [0.1381743 , 0.51270306, 0.23926187],\n","         [0.10138071, 0.85308504, 0.5666609 ]],\n","\n","        [[0.35855186, 0.85794806, 0.11733317],\n","         [0.15380323, 0.8718302 , 0.16833043],\n","         [0.2348131 , 0.6475694 , 0.26320732],\n","         [0.9827808 , 0.95520437, 0.7281177 ]]]], dtype=float32)>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["b = tf.random.uniform(shape=(3,2,4,3))\n","b"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{},"colab_type":"code","id":"gyzlUiPuOMYv","outputId":"6398669a-01d9-4d1a-819f-4c1ea453d852"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2, 2, 3), dtype=float32, numpy=\n","array([[[[0.956856  , 0.39216593, 0.54531276],\n","         [1.5148717 , 1.337302  , 1.2881459 ]],\n","\n","        [[0.56568766, 1.0043776 , 1.2066133 ],\n","         [0.52643305, 0.7353326 , 1.1618981 ]]],\n","\n","\n","       [[[1.5493038 , 1.4546263 , 1.400547  ],\n","         [0.82065266, 1.1117872 , 1.0441172 ]],\n","\n","        [[1.211664  , 1.9053063 , 0.9544655 ],\n","         [0.9565996 , 1.588706  , 0.97143495]]],\n","\n","\n","       [[[0.26849398, 0.9687656 , 0.64320725],\n","         [0.15751547, 0.8350689 , 0.56639093]],\n","\n","        [[1.0119966 , 1.8679082 , 0.72321457],\n","         [0.76779425, 1.5289398 , 0.5650518 ]]]], dtype=float32)>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["tf.matmul(a,b) # (3*2*2*4)@(3*2*4*3)=(3*2*2*3)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vhFWsCP1OMY0"},"source":["## 1. 4 Transpose\n"," - matrix transpose."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{},"colab_type":"code","id":"chFxqDYUOMY0","outputId":"8f695cd4-a9fa-4e36-9775-6f13dad25ac1"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.43253863, 0.15748894],\n","       [0.00462377, 0.07180631],\n","       [0.30012047, 0.655772  ]], dtype=float32)>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2))\n","a"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{},"colab_type":"code","id":"hcgW9_ctOMY5","outputId":"7cee185b-054f-4300-d5b9-48b9665ce266"},"outputs":[{"data":{"text/plain":["TensorShape([3, 2])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["a.shape"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{},"colab_type":"code","id":"2qoOVv8pOMY9","outputId":"9e01e07a-026e-499e-ac90-781bd8edd78e"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n","array([[0.43253863, 0.00462377, 0.30012047],\n","       [0.15748894, 0.07180631, 0.655772  ]], dtype=float32)>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tf.transpose(a)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BwTCIpAQOMZA"},"source":["We have a \"perm\" argument for transpose function, in that you can define your own way to change rows and column positions. as shown below."]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{},"colab_type":"code","id":"iMyw2YIAOMZB","outputId":"62093672-34a0-4f2d-a0db-3c7648ec3485"},"outputs":[{"data":{"text/plain":["TensorShape([3, 2, 5, 4])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2,5,4))\n","a.shape"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{},"colab_type":"code","id":"GUquLpjJOMZG"},"outputs":[],"source":["a_transpose = tf.transpose(a, perm=[0, 2, 1, 3])"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{},"colab_type":"code","id":"4K7g_bAsOMZK","outputId":"ef86f009-d814-4b24-cc5b-abee06aa420a"},"outputs":[{"data":{"text/plain":["TensorShape([3, 5, 2, 4])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["a_transpose.shape"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zmDQktLGOMZO"},"source":["My transposed matrix dim changed based on pem values( we transposed 1 and 2 axis only). you can check below example in that we chnaged all the axis."]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{},"colab_type":"code","id":"pD1ytjz0OMZP","outputId":"b2acaecd-9ef3-4263-9eca-c8f91958cbfe"},"outputs":[{"data":{"text/plain":["TensorShape([3, 2, 5, 4])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2,5,4))\n","a.shape"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{},"colab_type":"code","id":"IagVMwNjOMZR"},"outputs":[],"source":["a_transpose = tf.transpose(a, perm=[3, 2, 1, 0])"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{},"colab_type":"code","id":"rbcCTZuiOMZU","outputId":"9d0c0432-706c-4b04-c0bb-fab83d6192ff"},"outputs":[{"data":{"text/plain":["TensorShape([4, 5, 2, 3])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["a_transpose.shape"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_galZ10JOMZX"},"source":["## 1. 4 Element wise operation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"luaCDJ_8OMZY"},"source":["### 1.4.1 Multiply Respective elements in two matrices\n","Ex: \n","\n","A = [[1 2],\n","     [3,4]]\n","\n","B = [[5,6],\n","     [7,8]]\n","\n","we want A*B as \n","[A[0][0]*B[0][0], A[0][1]*B[0][1]\n","A[1][0]*B[1][0], A[1][1]*B[1][1]]\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{},"colab_type":"code","id":"rIOB8zyIOMZZ","outputId":"3ec7c53e-9347-4950-8359-443895d507b8"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.19848382, 0.2280451 ],\n","       [0.5100577 , 0.8891454 ],\n","       [0.11885726, 0.86677253]], dtype=float32)>"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2))\n","a"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{},"colab_type":"code","id":"kJxr1BFgOMZc","outputId":"f1404940-d2f2-4f8e-d887-6863e9112890"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.8315736 , 0.677057  ],\n","       [0.30718982, 0.5469301 ],\n","       [0.16735661, 0.983897  ]], dtype=float32)>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["b = tf.random.uniform(shape=(3,2))\n","b"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{},"colab_type":"code","id":"qszNHNK8OMZe","outputId":"b2cf32a9-29dd-485b-e845-b8e1e788324a"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.1650539 , 0.15439954],\n","       [0.15668453, 0.48630035],\n","       [0.01989155, 0.85281485]], dtype=float32)>"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["a * b"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{},"colab_type":"code","id":"PLWk8lQkOMZg","outputId":"7e4d4b95-e10e-48a2-e123-5ac3b5ada568"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.1650539 , 0.15439954],\n","       [0.15668453, 0.48630035],\n","       [0.01989155, 0.85281485]], dtype=float32)>"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["tf.multiply(a, b)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k6KnJSQ9OMZi"},"source":["We can do a*b or we can use tf.multiply"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z8dLCOEaOMZj"},"source":["## 1.5 Expanding Dimensions"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{},"colab_type":"code","id":"GrSkSucPOMZj","outputId":"66be7e9f-b2d9-4045-9b1f-a85e35d3cd1a"},"outputs":[{"data":{"text/plain":["TensorShape([3, 2])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2))\n","a.shape"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{},"colab_type":"code","id":"Ea9KHLbSOMZm"},"outputs":[],"source":["a_add = tf.expand_dims(a, axis=1)#we are adding an additional axis at 1st dim"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{},"colab_type":"code","id":"YfcxwikXOMZq","outputId":"b735dccc-a254-47b9-9ee0-c0077237deb9"},"outputs":[{"data":{"text/plain":["TensorShape([3, 1, 2])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["a_add.shape"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{},"colab_type":"code","id":"2q_MkdrgOMZw","outputId":"dd3d6bd9-8bd4-441e-c51e-8a4d0432770c"},"outputs":[{"data":{"text/plain":["TensorShape([3, 2])"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,2))\n","a.shape"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{},"colab_type":"code","id":"A3UzTFUFOMZ0"},"outputs":[],"source":["a_add = tf.expand_dims(a, axis=2)#we are adding an additional axis at 2nd dim"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{},"colab_type":"code","id":"fc4R99CxOMZ2","outputId":"fbb6308d-198b-4437-af9d-1afb3d2c6b72"},"outputs":[{"data":{"text/plain":["TensorShape([3, 2, 1])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["a_add.shape"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OQayeY4wOMZ5"},"source":["## 1.6 Squeezing dimensions"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AVomMzI6OMZ6"},"source":["\n","Note that we can squeeze along with the axis with shape 1\n","\n","Ex: \n","A.shape= [3,4,1] ==> we can squeez it on axis=2 will give [3,4]\n","A.shape= [3,1,4] ==> we can squeez it on axis=1 will give [3,4]\n","A.shape= [1,3,4] ==> we can squeez it on axis=0 will give [3,4]\n","A.shape= [2,3,4] ==> we can't squeez it on any of the axis"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{},"colab_type":"code","id":"FYqN12oiOMZ9","outputId":"18ea673d-f869-4d7a-e369-4bcc976cde32"},"outputs":[{"data":{"text/plain":["TensorShape([3, 1, 4])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.random.uniform(shape=(3,1,4))\n","a.shape"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{},"colab_type":"code","id":"-H6UcJfJOMaA"},"outputs":[],"source":["a_squ = tf.squeeze(a, axis=1)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{},"colab_type":"code","id":"RTxBvofpOMaD","outputId":"60a18069-76fd-405a-97e2-47962e7555f1","scrolled":true},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n","array([[0.33686757, 0.09825051, 0.04980445, 0.79571044],\n","       [0.90207875, 0.99290466, 0.4721912 , 0.02059007],\n","       [0.4293635 , 0.7167231 , 0.4856181 , 0.1924429 ]], dtype=float32)>"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["a_squ"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_SArBwQROMaE"},"source":["## 1.7 Reshaping of tensors\n","\n","<a href='https://www.tensorflow.org/api_docs/python/tf/reshape'> check the documentation </a>"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{},"colab_type":"code","id":"wEjdOLJROMaF","outputId":"11764a1b-d324-457d-dd95-2e23e69169ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5, 3, 4) (15, 4)\n"]}],"source":["a = tf.random.uniform(shape=(5,3,4))\n","# tf.reshape(tensor, [reshape dimensions]])\n","b = tf.reshape(a, [a.shape[0]*a.shape[1],a.shape[2]])\n","print(a.shape, b.shape)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"USHug53cOMaI"},"source":["# 2. Call Backs"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{},"colab_type":"code","id":"pYFub-clOMaJ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{},"colab_type":"code","id":"Edk77ekZOMaM"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n","# if you observe the input shape its 3 dimensional vector\n","# for each image we have a (28*28) vector\n","# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) \n","Y_train = tf.keras.utils.to_categorical(y_train, 10) \n","Y_test = tf.keras.utils.to_categorical(y_test, 10)"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{},"colab_type":"code","id":"9zuUwtN0OMaO","outputId":"da064def-dab6-4da9-a240-a4ec16f7dfdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 784)\n","(10000, 784)\n","(60000, 10)\n","(10000, 10)\n"]}],"source":["print(X_train.shape)\n","print(X_test.shape)\n","print(Y_train.shape)\n","print(Y_test.shape)"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{},"colab_type":"code","id":"U6sg7WeVOMaP"},"outputs":[],"source":["from tensorflow.keras.layers import Dense,Input,Activation\n","from tensorflow.keras.models import Model\n","import random as rn"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t_psPfAhOMaR"},"source":["## 2.1 Writing custom call backs"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N2zS015yOMaR"},"source":["In Keras, Callback is a python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Up_jqqGfOMaS"},"source":["\n","<b>Writing Call Backs</b> - You can inherit from <b>`tf.keras.callbacks.Callback`</b>, Copied the code for callback class from tensorflow documentation and pasted in below cell, you can check that code. It has many methods like batch/epoch_begin/end. so you can do manupulate the model parameters or print the required outputs using these methods. The `logs` dict contains the loss value, and all the metrics at the end of a batch or epoch\n","\n","> <a href='https://www.w3schools.com/python/python_inheritance.asp'> Do Read this Blog to understand how to inhert other classes </a>"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{},"colab_type":"code","id":"Cv88yZ_pOMaT"},"outputs":[],"source":["class Callback(object):\n","    \n","    \"\"\"Abstract base class used to build new callbacks.\n","      Attributes:\n","          params: dict. Training parameters\n","              (eg. verbosity, batch size, number of epochs...).\n","          model: instance of `keras.models.Model`.\n","              Reference of the model being trained.\n","          validation_data: Deprecated. Do not use.\n","      The `logs` dictionary that callback methods\n","      take as argument will contain keys for quantities relevant to\n","      the current batch or epoch.\n","      Currently, the `.fit()` method of the `Model` class\n","      will include the following quantities in the `logs` that\n","      it passes to its callbacks:\n","          on_epoch_end: logs include `acc` and `loss`, and\n","          optionally include `val_loss`\n","          (if validation is enabled in `fit`), and `val_acc`\n","          (if validation and accuracy monitoring are enabled).\n","          on_batch_begin: logs include `size`,\n","          the number of samples in the current batch.\n","          on_batch_end: logs include `loss`, and optionally `acc`\n","            (if accuracy monitoring is enabled).\n","      \"\"\"\n","\n","    def __init__(self):\n","        self.validation_data = None\n","        self.model = None\n","        # Whether this Callback should only run on the chief worker in a\n","        # Multi-Worker setting.\n","        # TODO(omalleyt): Make this attr public once solution is stable.\n","        self._chief_worker_only = None\n","\n","    def set_params(self, params):\n","        self.params = params\n","\n","    def set_model(self, model):\n","        self.model = model\n","\n","    def on_batch_begin(self, batch, logs=None):\n","        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n","\n","    def on_batch_end(self, batch, logs=None):\n","        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        \"\"\"Called at the start of an epoch.\n","        Subclasses should override for any actions to run. This function should only\n","        be called during TRAIN mode.\n","        Arguments:\n","            epoch: integer, index of epoch.\n","            logs: dict. Currently no data is passed to this argument for this method\n","              but that may change in the future.\n","        \"\"\"\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        \"\"\"Called at the end of an epoch.\n","        Subclasses should override for any actions to run. This function should only\n","        be called during TRAIN mode.\n","        Arguments:\n","            epoch: integer, index of epoch.\n","            logs: dict, metric results for this training epoch, and for the\n","              validation epoch if validation is performed. Validation result keys\n","              are prefixed with `val_`.\n","        \"\"\"\n","\n","    def on_train_batch_begin(self, batch, logs=None):\n","        \"\"\"Called at the beginning of a training batch in `fit` methods.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            batch: integer, index of batch within the current epoch.\n","            logs: dict. Has keys `batch` and `size` representing the current batch\n","              number and the size of the batch.\n","        \"\"\"\n","        # For backwards compatibility.\n","        self.on_batch_begin(batch, logs=logs)\n","\n","    def on_train_batch_end(self, batch, logs=None):\n","        \"\"\"Called at the end of a training batch in `fit` methods.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            batch: integer, index of batch within the current epoch.\n","            logs: dict. Metric results for this batch.\n","        \"\"\"\n","        # For backwards compatibility.\n","        self.on_batch_end(batch, logs=logs)\n","\n","    def on_test_batch_begin(self, batch, logs=None):\n","        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n","        Also called at the beginning of a validation batch in the `fit`\n","        methods, if validation data is provided.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            batch: integer, index of batch within the current epoch.\n","            logs: dict. Has keys `batch` and `size` representing the current batch\n","                  number and the size of the batch.\n","        \"\"\"\n","\n","    def on_test_batch_end(self, batch, logs=None):\n","        \"\"\"Called at the end of a batch in `evaluate` methods.\n","        Also called at the end of a validation batch in the `fit`\n","        methods, if validation data is provided.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            batch: integer, index of batch within the current epoch.\n","            logs: dict. Metric results for this batch.\n","        \"\"\"\n","\n","    def on_predict_batch_begin(self, batch, logs=None):\n","        \"\"\"Called at the beginning of a batch in `predict` methods.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            batch: integer, index of batch within the current epoch.\n","            logs: dict. Has keys `batch` and `size` representing the current batch\n","                  number and the size of the batch.\n","        \"\"\"\n","\n","    def on_predict_batch_end(self, batch, logs=None):\n","        \"\"\"Called at the end of a batch in `predict` methods.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            batch: integer, index of batch within the current epoch.\n","            logs: dict. Metric results for this batch.\n","        \"\"\"\n","\n","    def on_train_begin(self, logs=None):\n","        \"\"\"Called at the beginning of training.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            logs: dict. Currently no data is passed to this argument for this method\n","                  but that may change in the future.\n","        \"\"\"\n","\n","    def on_train_end(self, logs=None):\n","        \"\"\"Called at the end of training.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            logs: dict. Currently no data is passed to this argument for this method\n","                  but that may change in the future.\n","        \"\"\"\n","\n","    def on_test_begin(self, logs=None):\n","        \"\"\"Called at the beginning of evaluation or validation.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            logs: dict. Currently no data is passed to this argument for this method\n","              but that may change in the future.\n","        \"\"\"\n","\n","    def on_test_end(self, logs=None):\n","        \"\"\"Called at the end of evaluation or validation.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            logs: dict. Currently no data is passed to this argument for this method\n","              but that may change in the future.\n","        \"\"\"\n","\n","    def on_predict_begin(self, logs=None):\n","        \"\"\"Called at the beginning of prediction.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            logs: dict. Currently no data is passed to this argument for this method\n","              but that may change in the future.\n","        \"\"\"\n","\n","    def on_predict_end(self, logs=None):\n","        \"\"\"Called at the end of prediction.\n","        Subclasses should override for any actions to run.\n","        Arguments:\n","            logs: dict. Currently no data is passed to this argument for this method\n","              but that may change in the future.\n","    \"\"\""]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{},"colab_type":"code","id":"pfZUPJ01OMah"},"outputs":[],"source":["class LossHistory(tf.keras.callbacks.Callback):\n","    \n","    def on_train_begin(self, logs={}):\n","        ## on begin of training, we are creating a instance varible called history\n","        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n","        self.history={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n","        \n","    def on_epoch_end(self, epoch, logs={}):\n","        ## on end of each epoch, we will get logs and update the self.history dict\n","        self.history['loss'].append(logs.get('loss'))\n","        self.history['acc'].append(logs.get('acc'))\n","        if logs.get('val_loss', -1) != -1:\n","            self.history['val_loss'].append(logs.get('val_loss'))\n","        if logs.get('val_acc', -1) != -1:\n","            self.history['val_acc'].append(logs.get('val_acc'))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UzEyvZg-OMaj"},"source":["> in the above function we have written logs={}, which means the logs is a dictionary and the keys present will the same values that gets printed while you train your model i.e model.fit()\n","<img src='https://i.imgur.com/fAiHfe7.png'>"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{},"colab_type":"code","id":"Ca3J3ySeOMak","outputId":"7c7b689b-4e82-4f62-9cef-9882894ee2da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","3750/3750 [==============================] - 7s 2ms/step - loss: 1.2397 - accuracy: 0.5588 - val_loss: 0.9407 - val_accuracy: 0.6714\n","Epoch 2/3\n","3750/3750 [==============================] - 6s 2ms/step - loss: 0.9707 - accuracy: 0.6655 - val_loss: 0.9870 - val_accuracy: 0.6827\n","Epoch 3/3\n","3750/3750 [==============================] - 6s 1ms/step - loss: 0.8815 - accuracy: 0.7050 - val_loss: 0.8340 - val_accuracy: 0.7384\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d266250310>"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["#Input layer\n","input_layer = Input(shape=(784,))\n","#Dense hidden layer\n","layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n","#output layer\n","output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n","#Creating a model\n","model = Model(inputs=input_layer,outputs=output)\n","\n","\n","#Callbacks\n","history_own = LossHistory()\n","\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks=[history_own])\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{},"colab_type":"code","id":"5nzuF0OPOMam","outputId":"4c4de85a-6095-4938-e92d-cc83993aad5a"},"outputs":[{"data":{"text/plain":["{'loss': [1.2397392988204956, 0.970748245716095, 0.881500780582428],\n"," 'acc': [None, None, None],\n"," 'val_loss': [0.940748929977417, 0.9869956970214844, 0.8340421915054321],\n"," 'val_acc': []}"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["history_own.history"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"riBZE6ZrOMao"},"source":["<b>Writing the call back to terminate training if loss is 'NaN'</b>"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{},"colab_type":"code","id":"cMYmZMVeOMap"},"outputs":[],"source":["class TerminateNaN(tf.keras.callbacks.Callback):\n","        \n","    def on_epoch_end(self, epoch, logs={}):\n","        loss = logs.get('loss')\n","        if loss is not None:\n","            if np.isnan(loss) or np.isinf(loss):\n","                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n","                self.model.stop_training = True"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vh4umPy9OMaq"},"source":["## 2.2 Using tensorflow call backs"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qv9epZaHOMaq"},"source":["There are some callbacks which are implemented in the Tensorflow\n","\n","<b>ModelCheckpoint</b> - Save the model after every epoch. You can check documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\">here</a>"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{},"colab_type":"code","id":"OvIlgI2ROMas"},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{},"colab_type":"code","id":"h3-DSrb2OMau","outputId":"0f12e82c-e169-4cd0-bf8a-c938384dfae8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","3724/3750 [============================>.] - ETA: 0s - loss: 1.3577 - accuracy: 0.5231\n","Epoch 1: val_loss improved from inf to 1.28893, saving model to model_save\\weights-01-0.5237.hdf5\n","3750/3750 [==============================] - 7s 2ms/step - loss: 1.3579 - accuracy: 0.5232 - val_loss: 1.2889 - val_accuracy: 0.5237\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jrajp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/5\n","3737/3750 [============================>.] - ETA: 0s - loss: 1.0573 - accuracy: 0.6318\n","Epoch 2: val_loss improved from 1.28893 to 1.02395, saving model to model_save\\weights-02-0.6347.hdf5\n","3750/3750 [==============================] - 6s 2ms/step - loss: 1.0581 - accuracy: 0.6316 - val_loss: 1.0239 - val_accuracy: 0.6347\n","Epoch 3/5\n","3734/3750 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.6713\n","Epoch 3: val_loss improved from 1.02395 to 0.82880, saving model to model_save\\weights-03-0.7222.hdf5\n","3750/3750 [==============================] - 6s 2ms/step - loss: 0.9361 - accuracy: 0.6717 - val_loss: 0.8288 - val_accuracy: 0.7222\n","Epoch 4/5\n","3718/3750 [============================>.] - ETA: 0s - loss: 0.8609 - accuracy: 0.7045\n","Epoch 4: val_loss improved from 0.82880 to 0.79717, saving model to model_save\\weights-04-0.7268.hdf5\n","3750/3750 [==============================] - 6s 2ms/step - loss: 0.8603 - accuracy: 0.7046 - val_loss: 0.7972 - val_accuracy: 0.7268\n","Epoch 5/5\n","3718/3750 [============================>.] - ETA: 0s - loss: 0.7587 - accuracy: 0.7425\n","Epoch 5: val_loss did not improve from 0.79717\n","3750/3750 [==============================] - 6s 2ms/step - loss: 0.7603 - accuracy: 0.7420 - val_loss: 0.8249 - val_accuracy: 0.7239\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d267c6bd30>"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["#Input layer\n","input_layer = Input(shape=(784,))\n","#Dense hidden layer\n","layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n","#output layer\n","output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n","#Creating a model\n","model = Model(inputs=input_layer,outputs=output)\n","\n","\n","#Callbacks\n","#file path, it saves the model in the 'model_save' folder and we are naming model with epoch number \n","#and val acc to differtiate with other models\n","#we have to create model_save folder before running the code.\n","filepath=\"model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n","\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","\n","model.compile(optimizer=optimizer,\n","              loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=[checkpoint])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GfAHPmifOMax"},"source":["If you need 4th epoch model, you can load that model as below. It saves optimizer state as well. so noo need to recompile."]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{},"colab_type":"code","id":"r0AIY28BOMaz"},"outputs":[],"source":["model.load_weights('model_save/weights-04-0.7268.hdf5')#change this with your name which you got in above output"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{},"colab_type":"code","id":"lJ7A1PJHOMa0","outputId":"22cef2e7-19b9-452f-aaad-8ab3618451d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["1875/1875 [==============================] - 3s 1ms/step - loss: 0.7541 - accuracy: 0.7491\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d267fa61f0>"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_train,Y_train)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yrHJBrPCOMa3"},"source":["### 2.2.1 EarlyStopping:\n","\n","Stop training when a monitored quantity has stopped improving. You can check the documentatin <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\">here</a>"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{},"colab_type":"code","id":"FS1jubUuOMa3"},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{},"colab_type":"code","id":"_BxU-droOMa6","outputId":"4f77741c-cd29-4173-9d08-5ab8b7ad6a48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","3750/3750 [==============================] - 7s 2ms/step - loss: 1.2617 - accuracy: 0.5558 - val_loss: 1.0553 - val_accuracy: 0.6275\n","Epoch 2/10\n","3750/3750 [==============================] - 6s 2ms/step - loss: 1.0738 - accuracy: 0.6179 - val_loss: 1.0203 - val_accuracy: 0.6540\n","Epoch 2: early stopping\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d2797d5f70>"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["#Input layer\n","input_layer = Input(shape=(784,))\n","#Dense hidden layer\n","layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n","#output layer\n","output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n","#Creating a model\n","model = Model(inputs=input_layer,outputs=output)\n","\n","#you can monitor any quantity (here i am monitoring val_loss), you can give any number for patience based on your need. \n","#i am terminating training if my validation loss incresing at once than previous loss. so maintained 1. you can give min delta\n","#an absolute change of less than min_delta, will count as no improvement. i maintained 0.35 because i don't want to run \n","#so many epoch to see termination\n","earlystop = EarlyStopping(monitor='val_loss', min_delta=0.35, patience=1, verbose=1)\n","\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","\n","model.compile(optimizer=optimizer,\n","              loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.fit(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test),batch_size=16,callbacks=[earlystop])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"05WyP1W2OMa9"},"source":["It stopped at 2nd epoch only. You can use this early stopping to get best model than overfitted model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AjQJADh8OMa-"},"source":["### 2.2.2 LearningRateScheduler:\n","You can schedule learning rate for every epoch. You can decrease or increase the learning rate based on epoch number."]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{},"colab_type":"code","id":"er-L_eZIOMa_"},"outputs":[],"source":["from tensorflow.keras.callbacks import LearningRateScheduler"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{},"colab_type":"code","id":"3YONlCwyOMbA"},"outputs":[],"source":["def changeLearningRate(epoch):\n","    initial_learningrate=0.1\n","    changed = initial_learningrate*(1-0.1)**epoch\n","    return changed"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{},"colab_type":"code","id":"hS18HNhtOMbC"},"outputs":[],"source":["changed_lr = []\n","for i in range(1,50):\n","    changed_lr.append(changeLearningRate(i))"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{},"colab_type":"code","id":"T7JjoQ2aOMbE"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{},"colab_type":"code","id":"PSdopgjfOMbG","outputId":"a21ca1de-08c0-4e61-b0af-b0c89075e0ee"},"outputs":[{"data":{"text/plain":["Text(0.5, 0, 'epoch number')"]},"execution_count":68,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(changed_lr)\n","plt.ylabel('learning_rate')\n","plt.xlabel('epoch number')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YSvB3InnOMbH"},"source":["If you check above figure, learning rate is decreasing if my epoch number is increasing. I am using same function to schedule our learning rate based on epoch number. You can write your own function or you can write custom call back to decrease the learning rate based on val_loss/acc. \n","In the above function, i have implemented exponential decay with decay rate 0.1, you can check that <a href=\"https://mathbitsnotebook.com/Algebra2/Exponential/EXGrowthDecay.html\">here</a>"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{},"colab_type":"code","id":"vTZCQXQ_OMbH","outputId":"fc89d5ee-2db1-4376-bade-053be24b01de"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.1.\n","Epoch 1/3\n","3750/3750 [==============================] - 6s 2ms/step - loss: 2.0548 - accuracy: 0.3201 - val_loss: 2.0543 - val_accuracy: 0.3815 - lr: 0.1000\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.09000000000000001.\n","Epoch 2/3\n","3750/3750 [==============================] - 6s 2ms/step - loss: 1.9825 - accuracy: 0.3303 - val_loss: 2.2212 - val_accuracy: 0.3260 - lr: 0.0900\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.08100000000000002.\n","Epoch 3/3\n","3750/3750 [==============================] - 6s 2ms/step - loss: 1.9782 - accuracy: 0.3408 - val_loss: 1.7286 - val_accuracy: 0.4163 - lr: 0.0810\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d266241dc0>"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["#Input layer\n","input_layer = Input(shape=(784,))\n","#Dense hidden layer\n","layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n","#output layer\n","output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n","#Creating a model\n","model = Model(inputs=input_layer,outputs=output)\n","\n","lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n","              loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[lrschedule])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fVm_fKElOMbK"},"source":["### 2.2.3 ReduceLROnPlateau\n","It is similar to EarlyStopping, you can reduce your Learning rate by some factor if my val_loss/acc is not improving. You can check the documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\">here</a>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V35jamIuOMbL"},"source":["There are many pre built call backs are available in Tensorflow, you can check those in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\">this</a> link.\n","\n","You can give as many callbacks you want while training the model as given below."]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{},"colab_type":"code","id":"ts8yx-dwOMbO","outputId":"a841d5e3-0b9f-4916-b35e-8a98337b8c79"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.1.\n","Epoch 1/5\n","3746/3750 [============================>.] - ETA: 0s - loss: 2.3180 - accuracy: 0.1960\n","Epoch 1: val_loss improved from inf to 2.57491, saving model to model_save\\weights-01-0.1715.hdf5\n","3750/3750 [==============================] - 7s 2ms/step - loss: 2.3182 - accuracy: 0.1959 - val_loss: 2.5749 - val_accuracy: 0.1715 - lr: 0.1000\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.09000000000000001.\n","Epoch 2/5\n","  35/3750 [..............................] - ETA: 5s - loss: 2.4783 - accuracy: 0.1750     "]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jrajp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["3745/3750 [============================>.] - ETA: 0s - loss: 2.2615 - accuracy: 0.2028\n","Epoch 2: val_loss improved from 2.57491 to 2.35044, saving model to model_save\\weights-02-0.1896.hdf5\n","3750/3750 [==============================] - 6s 2ms/step - loss: 2.2620 - accuracy: 0.2026 - val_loss: 2.3504 - val_accuracy: 0.1896 - lr: 0.0900\n","Epoch 2: early stopping\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d26b0f3430>"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["#Input layer\n","input_layer = Input(shape=(784,))\n","#Dense hidden layer\n","layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n","#output layer\n","output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n","#Creating a model\n","model = Model(inputs=input_layer,outputs=output)\n","\n","#create a call back list\n","lrschedule = LearningRateScheduler(changeLearningRate, verbose=0.1)\n","earlystop = EarlyStopping(monitor='val_loss', min_delta=0.25, patience=1, verbose=1)\n","filepath=\"model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, \n","                             save_best_only=True, mode='auto')\n","\n","\n","# here we are creating a list with all the callbacks we want\n","callback_list = [lrschedule, earlystop, checkpoint]\n","\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n","              loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=callback_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["0fjRvsmIOMYG","vhFWsCP1OMY0","_galZ10JOMZX","luaCDJ_8OMZY","z8dLCOEaOMZj","OQayeY4wOMZ5","_SArBwQROMaE"],"name":"Call_Backs_Reference.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}
